# Utilities to generate training data for the SV detecting NN.
# cmdoret, 20190131

import numpy as np
import pandas as pd
from Bio import SeqIO, Seq
from hicstuff import view as hcv
import json


class GenomeMixer(object):
    """
    Handles genome edition through different types of structural variations
    
    Examples
    --------
        mix = GenomeMixer("genome.fasta", "config.json", "profile="Dmel")
        mix.generate_sv()
        mix.edit_genome("new_genome.fasta")
    
    Attributes
    ----------
    genome_path : str
        Path to the input genome to mix.
    config_path : str
        Path to the JSON config file to use for generating SVs.
    config : dict
        SV properties in a nested dictionary, loaded from a single profile in
        the config file.
    chromsizes : dict
        Contains the size of each chromosome in the format {chrom: len, ...}.
    sv : pandas.DataFrame
        Contains all structural variants, once generated by `generate_sv()`

    """

    def __init__(self, genome_path, config_path, config_profile=None):
        self.config_path = config_path
        self.config = self.load_profile(profile=config_profile)
        self.genome_path = genome_path
        self.chromsizes = self.load_chromsizes(self.genome_path)
        self.sv = None

    def load_profile(self, profile=None):
        """
        Load SV profile from a JSON config file. The top level JSON object is a
        profile. A config file can have multiple profiles, but only one will be
        loaded. Each profile contains the 'SV_freq' property, which gives the
        number of SV per bp, and the `SV_types` object. The SV_types object
        contains one object per SV type. Each SV contains multiple properties.

        Parameters
        ----------
        profile : str
            Name of the profile to load in the config file.

        Returns
        -------
        dict :
            A dictionary of SV types structured like 
            {"sv_type":{"property": value, ...}, ...}
        """
        config = json.load(open(self.config_path, "r"))
        if not profile:
            if len(config) > 1:
                print(
                    "You must specify a profile name if multiple profiles "
                    "appear in the JSON config file"
                )
                raise ValueError
            else:
                profile = config.keys()[0]

        return config[profile]

    @staticmethod
    def load_chromsizes(path):
        """
        Loads a fasta file and returns a chromsizes dict.

        Parameters
        ----------
        path : str
            Path to the FASTA file to load.

        Returns
        -------
        chromsizes : dict
            A dictionary of chromosomes sizes format {"chrom": size}


        """
        records = SeqIO.parse(path, format="fasta")
        return {rec.id: len(str(rec.seq)) for rec in records}

    def generate_sv(self):
        """
        Generates random structural variations, based on the parameters loaded
        from the instance's config file.
        # NOTE: Currently only implemented for inversions.

        Returns
        -------
        pandas.DataFrame :
            A dataframe where each row is a SV. columns represent
            sv_type, chrom, start, end.
        """
        # Relative abundance of each event type (placeholder values)
        # rel_abun = {"INV": 8, "DEL": 400, "DUP": 60, "INS": 160, "CNV": 350}
        for chrom, size in self.chromsizes.items():
            n_sv = size * self.config["SV_freq"]
            out_sv = pd.DataFrame(np.empty((int(n_sv), 4)))
            out_sv.columns = ["sv_type", "chrom", "start", "end"]
            sv_count = 0
            for sv_name, sv_char in self.config["SV_types"].items():
                # multiply proportion of SV type by total SV freq desired to
                # get number of events of this type.
                n_event = int(n_sv * sv_char["prop"])
                for _ in range(n_event):
                    # Start position is random and length is picked from a normal
                    # distribution centered around mean length.
                    start = np.random.randint(size)
                    end = start + np.random.normal(
                        loc=sv_char["mean_size"], scale=sv_char["sd_size"]
                    )
                    # Make sure the inversion does not go beyond chromosome.
                    end = min(size, end)
                    out_sv.iloc[sv_count, :] = (sv_name, chrom, start, end)
                    sv_count += 1

        self.sv = out_sv

    def edit_genome(self, fasta_out):
        """
        Given a fasta file and a dataframe of structural variants and their
        positions, generate a new genome by applying the input changes.

        Parameters
        ----------
        fasta_out : str
            Path where the edited genome will be written in fasta format.
        """
        with open(fasta_out, "w") as fa_out:
            for chrom in SeqIO.parse(self.genome_path, format="fasta"):
                mutseq = Seq.MutableSeq(str(chrom.seq))
                for row_num in range(self.sv.shape[0]):
                    row = self.sv.iloc[row_num, :]
                    sv_type = row.sv_type
                    chr, start, end = row.chrom, int(row.start), int(row.end)
                    # NOTE: Only implemented for inversions for now.
                    if sv_type == "INV":
                        if chr == chrom.id:
                            mutseq[start:end] = mutseq[end - 1 : start - 1 : -1]
                chrom = SeqIO.SeqRecord(seq=mutseq, id=chrom.id, description="")
                SeqIO.write(chrom, fa_out, format="fasta")


class MatrixSlicer(object):
    """
    Allows loading and slicing `hicstuff` Hi-C matrices to feed windows into a
    keras model.
    """

    def subset_mat(self, matrix, coords, labels, winsize=128, prop_negative=0.5):
        """
        Samples evenly sized windows from a matrix. Windows are centered around
        input coordinates. Windows and their associated labels are returned.

        Parameters
        ----------
        matrix : scipy.sparse.coo_matrix
            The Hi-C matrix as a 2D array in sparse format.
        coords : numpy.ndarray of ints
            Pairs of coordinates for which subsets should be generated. A window
            centered around each of these coordinates will be sampled. Dimensions
            are [N, 2].
        labels : numpy.ndarray of ints
            1D array of labels corresponding to the coords given.
        winsize : int
            Size of windows to sample from the matrix.
        prop_negative : float
            The proportion of windows without SVs desired. If set to 0.5, when given
            a list of 23 SV, the function will output 46 observations (windows); 23
            without SV (picked randomly in the matrix) and 23 with SV.

        Returns
        -------
        x : numpy.ndarray of floats
            The 3D feature vector to use as input in a keras model.
            Dimensions are [N, winsize, winsize].
        y : numpy.array of ints
            The 1D label vector of N values to use as prediction in a keras model.
        """

        h, w = matrix.shape
        i_w = int(h - winsize // 2)
        j_w = int(w - winsize // 2)
        sv_to_int = {"INV": 1, "DEL": 2, "INS": 3}
        # Only keep coords far enough from borders of the matrix
        valid_coords = np.where(
            (coords[:, 0] > int(winsize / 2))
            & (coords[:, 1] > int(winsize / 2))
            & (coords[:, 0] < i_w)
            & (coords[:, 1] < j_w)
        )[0]
        coords = coords[valid_coords, :]
        labels = labels[valid_coords]
        # Number of windows to generate (including negative windows)
        n_windows = int(coords.shape[0] // (1 - prop_negative))
        x = np.zeros((n_windows, winsize, winsize), dtype=np.float64)
        y = np.zeros(n_windows, dtype=np.int64)
        if winsize >= min(h, w):
            print("Window size must be smaller than the Hi-C matrix.")
        matrix = matrix.tocsr()
        halfw = winsize // 2
        # Getting SV windows
        for i in range(coords.shape[0]):
            c = coords[i, :]
            win = matrix[
                (c[0] - halfw) : (c[0] + halfw), (c[1] - halfw) : (c[1] + halfw)
            ]
            x[i, :, :] = hcv.sparse_to_dense(win, remove_diag=False)
            y[i] = sv_to_int[labels[i]]
        # Getting negative windows
        neg_coords = set()
        for i in range(coords.shape[0], n_windows):
            tries = 0
            c = np.random.randint(winsize // 2, i_w)
            # this coordinate must not exist already
            while (c in coords[:, 0]) or (c in neg_coords):
                print("{} is already used. Trying another position...".format(c))
                # If unable to find new coords, just return output until here
                if tries > 100:
                    return x[:i, :, :], y[:i]
                c = np.random.randint(winsize // 2, i_w)
                neg_coords.add(c)
                tries += 1
            win = matrix[(c - halfw) : (c + halfw), (c - halfw) : (c + halfw)]
            x[i, :, :] = hcv.sparse_to_dense(win, remove_diag=False)
            y[i] = 0
        return x, y

    def pos_to_coord(self, sv_df, frags_df, bin_size):
        """
        Converts start - end genomic positions from structural variations to breakpoints
        in matrix coordinates.

        Parameters
        ----------
        sv_df : pandas.DataFrame
            A dataframe containg the type and genomic start-end coordinates of
            strucural variations as given by generate_sv().
        frags_df : pandas.DataFrame
            A dataframe containing the list of fragments of bins in the Hi-C matrix.
        bin_size : int
            The bin size used for the matrix.

        Returns
        -------
        breakpoints : numpy.array of int
            A N x 2 numpy array of numeric values representing X, Y coordinates of structural
            variations breakpoints in the matrix.
        labels : numpy.array of str
            An N X 1 array of labels corresponding to SV type.
        """
        # Get coordinates to match binning
        sv_df.start = (sv_df.start // bin_size) * bin_size
        sv_df.end = (sv_df.end // bin_size) * bin_size
        # Put start and end in the same column, 1 row / breakpoint
        s_df = sv_df.loc[:, ["sv_type", "chrom", "start"]]
        s_df.rename(index=str, columns={"start": "pos"}, inplace=True)
        e_df = sv_df.loc[:, ["sv_type", "chrom", "end"]]
        e_df.rename(index=str, columns={"end": "pos"}, inplace=True)
        sv_df = pd.concat([s_df, e_df]).reset_index(drop=True)
        # Assign matrix coordinate (fragment index) to each breakpoint
        frags_df["coord"] = frags_df.index
        sv_frags = sv_df.merge(
            frags_df,
            left_on=["chrom", "pos"],
            right_on=["chrom", "start_pos"],
            how="left",
        )
        breakpoints = np.vstack([sv_frags.coord, sv_frags.coord]).T
        breakpoints.astype(int)
        labels = np.array(sv_frags.sv_type.tolist())
        return breakpoints, labels
